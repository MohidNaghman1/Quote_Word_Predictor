{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quote Writer Using LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number</th>\n",
       "      <th>Quote</th>\n",
       "      <th>Author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The only thing we have to fear is fear itself.</td>\n",
       "      <td>Franklin D. Roosevelt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>The truth will set you free.</td>\n",
       "      <td>The Bible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>To be yourself in a world that is constantly t...</td>\n",
       "      <td>Ralph Waldo Emerson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Success is not final, failure is not fatal: It...</td>\n",
       "      <td>Winston S. Churchill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>The only way to do great work is to love what ...</td>\n",
       "      <td>Steve Jobs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Number                                              Quote  \\\n",
       "0       1     The only thing we have to fear is fear itself.   \n",
       "1       2                       The truth will set you free.   \n",
       "2       3  To be yourself in a world that is constantly t...   \n",
       "3       4  Success is not final, failure is not fatal: It...   \n",
       "4       5  The only way to do great work is to love what ...   \n",
       "\n",
       "                  Author  \n",
       "0  Franklin D. Roosevelt  \n",
       "1              The Bible  \n",
       "2    Ralph Waldo Emerson  \n",
       "3   Winston S. Churchill  \n",
       "4             Steve Jobs  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Quotes Dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 725 entries, 0 to 724\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Number  725 non-null    int64 \n",
      " 1   Quote   725 non-null    object\n",
      " 2   Author  725 non-null    object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 17.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Number', 'Quote', 'Author'], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Number'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Quote', 'Author'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Author\n",
       "Albert Einstein           98\n",
       "Buddha                    51\n",
       "Confucius                 50\n",
       "Thomas Edison             50\n",
       "Wayne Gretzky             50\n",
       "Theodore Roosevelt        50\n",
       "Nelson Mandela            50\n",
       "Lao Tzu                   50\n",
       "Abraham Lincoln           49\n",
       "Zig Ziglar                49\n",
       "Jimmy Dean                49\n",
       "Walt Disney               49\n",
       "Pablo Picasso             49\n",
       "Eleanor Roosevelt          2\n",
       "Robert Frost               2\n",
       "Steve Jobs                 2\n",
       "Helen Keller               2\n",
       "Franklin D. Roosevelt      2\n",
       "E.E. Cummings              1\n",
       "James Baldwin              1\n",
       "Sam Levenson               1\n",
       "Ralph Waldo Emerson        1\n",
       "Winston S. Churchill       1\n",
       "Dalai Lama                 1\n",
       "Albert Schweitzer          1\n",
       "George Eliot               1\n",
       "Mark Twain                 1\n",
       "Frank Sinatra              1\n",
       "John Lennon                1\n",
       "The Bible                  1\n",
       "Booker T. Washington       1\n",
       "Mahatma Gandhi             1\n",
       "Martin Luther King Jr.     1\n",
       "Norman Vincent Peale       1\n",
       "Joseph Campbell            1\n",
       "Audrey Hepburn             1\n",
       "Charles R. Swindoll        1\n",
       "Dr. Seuss                  1\n",
       "Mae West                   1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Author'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Quote     0\n",
       "Author    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(df['Quote'].str.len())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = max(df['Quote'].str.len())\n",
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes = df['Quote']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         The only thing we have to fear is fear itself.\n",
       "1                           The truth will set you free.\n",
       "2      To be yourself in a world that is constantly t...\n",
       "3      Success is not final, failure is not fatal: It...\n",
       "4      The only way to do great work is to love what ...\n",
       "                             ...                        \n",
       "720            Believe you can and you're halfway there.\n",
       "721    The mind is everything. What you think you bec...\n",
       "722    I have not failed. I've just found 10,000 ways...\n",
       "723    A journey of a thousand miles begins with a si...\n",
       "724          It always seems impossible until it's done.\n",
       "Name: Quote, Length: 725, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(quotes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'you': 1,\n",
       " 'the': 2,\n",
       " 'to': 3,\n",
       " 'it': 4,\n",
       " 'of': 5,\n",
       " 'a': 6,\n",
       " 'can': 7,\n",
       " 'is': 8,\n",
       " 'be': 9,\n",
       " 'have': 10,\n",
       " 'and': 11,\n",
       " 'but': 12,\n",
       " 'i': 13,\n",
       " 'not': 14,\n",
       " 'everything': 15,\n",
       " 'always': 16,\n",
       " \"can't\": 17,\n",
       " 'my': 18,\n",
       " 'do': 19,\n",
       " 'that': 20,\n",
       " 'what': 21,\n",
       " 'we': 22,\n",
       " 'only': 23,\n",
       " 'life': 24,\n",
       " 'success': 25,\n",
       " 'yourself': 26,\n",
       " 'else': 27,\n",
       " 'work': 28,\n",
       " \"don't\": 29,\n",
       " 'if': 30,\n",
       " 'change': 31,\n",
       " 'your': 32,\n",
       " 'as': 33,\n",
       " \"you're\": 34,\n",
       " 'believe': 35,\n",
       " \"i've\": 36,\n",
       " 'on': 37,\n",
       " \"it's\": 38,\n",
       " '10': 39,\n",
       " 'until': 40,\n",
       " 'with': 41,\n",
       " 'one': 42,\n",
       " 'mind': 43,\n",
       " 'become': 44,\n",
       " 'impossible': 45,\n",
       " 'thing': 46,\n",
       " 'making': 47,\n",
       " 'miss': 48,\n",
       " '100': 49,\n",
       " 'shots': 50,\n",
       " 'take': 51,\n",
       " 'halfway': 52,\n",
       " 'there': 53,\n",
       " 'why': 54,\n",
       " 'failed': 55,\n",
       " 'just': 56,\n",
       " 'found': 57,\n",
       " '000': 58,\n",
       " 'ways': 59,\n",
       " \"won't\": 60,\n",
       " 'journey': 61,\n",
       " 'thousand': 62,\n",
       " 'miles': 63,\n",
       " 'begins': 64,\n",
       " 'step': 65,\n",
       " 'think': 66,\n",
       " 'seems': 67,\n",
       " 'done': 68,\n",
       " 'dream': 69,\n",
       " 'are': 70,\n",
       " 'keep': 71,\n",
       " 'direction': 72,\n",
       " 'wind': 73,\n",
       " 'adjust': 74,\n",
       " 'sails': 75,\n",
       " 'reach': 76,\n",
       " 'destination': 77,\n",
       " 'standing': 78,\n",
       " 'between': 79,\n",
       " 'goal': 80,\n",
       " 'story': 81,\n",
       " 'telling': 82,\n",
       " 'achieve': 83,\n",
       " 'learn': 84,\n",
       " 'rules': 85,\n",
       " 'game': 86,\n",
       " 'then': 87,\n",
       " 'play': 88,\n",
       " 'better': 89,\n",
       " 'than': 90,\n",
       " 'anyone': 91,\n",
       " 'whatever': 92,\n",
       " 'good': 93,\n",
       " 'strive': 94,\n",
       " 'rather': 95,\n",
       " 'value': 96,\n",
       " 'really': 97,\n",
       " 'simple': 98,\n",
       " 'insist': 99,\n",
       " 'complicated': 100,\n",
       " 'imagine': 101,\n",
       " 'real': 102,\n",
       " 'single': 103,\n",
       " 'in': 104,\n",
       " 'world': 105,\n",
       " 'will': 106,\n",
       " 'something': 107,\n",
       " 'way': 108,\n",
       " 'love': 109,\n",
       " 'up': 110,\n",
       " 'best': 111,\n",
       " 'happiness': 112,\n",
       " 'our': 113,\n",
       " 'nothing': 114,\n",
       " 'fear': 115,\n",
       " 'itself': 116,\n",
       " 'constantly': 117,\n",
       " 'trying': 118,\n",
       " 'make': 119,\n",
       " 'greatest': 120,\n",
       " 'accomplishment': 121,\n",
       " 'great': 122,\n",
       " 'happens': 123,\n",
       " 'once': 124,\n",
       " 'about': 125,\n",
       " 'because': 126,\n",
       " 'tomorrow': 127,\n",
       " 'today': 128,\n",
       " 'present': 129,\n",
       " 'faced': 130,\n",
       " 'changed': 131,\n",
       " 'does': 132,\n",
       " 'matter': 133,\n",
       " 'how': 134,\n",
       " 'go': 135,\n",
       " 'us': 136,\n",
       " 'must': 137,\n",
       " 'future': 138,\n",
       " 'things': 139,\n",
       " 'lift': 140,\n",
       " 'or': 141,\n",
       " 'getting': 142,\n",
       " 'key': 143,\n",
       " 'truth': 144,\n",
       " 'set': 145,\n",
       " 'free': 146,\n",
       " 'final': 147,\n",
       " 'failure': 148,\n",
       " 'fatal': 149,\n",
       " 'courage': 150,\n",
       " 'continue': 151,\n",
       " 'counts': 152,\n",
       " 'when': 153,\n",
       " 'busy': 154,\n",
       " 'other': 155,\n",
       " 'plans': 156,\n",
       " 'live': 157,\n",
       " 'right': 158,\n",
       " 'enough': 159,\n",
       " 'thoughts': 160,\n",
       " 'three': 161,\n",
       " 'words': 162,\n",
       " 'sum': 163,\n",
       " 'learned': 164,\n",
       " 'goes': 165,\n",
       " 'out': 166,\n",
       " 'through': 167,\n",
       " 'cry': 168,\n",
       " 'over': 169,\n",
       " 'smile': 170,\n",
       " 'happened': 171,\n",
       " 'wish': 172,\n",
       " 'see': 173,\n",
       " 'yesterday': 174,\n",
       " 'history': 175,\n",
       " 'mystery': 176,\n",
       " 'gift': 177,\n",
       " 'which': 178,\n",
       " 'call': 179,\n",
       " 'ready': 180,\n",
       " 'made': 181,\n",
       " 'comes': 182,\n",
       " 'from': 183,\n",
       " 'own': 184,\n",
       " 'actions': 185,\n",
       " 'limit': 186,\n",
       " 'realization': 187,\n",
       " 'doubts': 188,\n",
       " 'slowly': 189,\n",
       " 'long': 190,\n",
       " 'stop': 191,\n",
       " '90': 192,\n",
       " 'react': 193,\n",
       " 'word': 194,\n",
       " 'says': 195,\n",
       " \"'i'm\": 196,\n",
       " \"possible'\": 197,\n",
       " 'let': 198,\n",
       " 'planned': 199,\n",
       " 'so': 200,\n",
       " 'accept': 201,\n",
       " 'waiting': 202,\n",
       " 'for': 203,\n",
       " 'belongs': 204,\n",
       " 'those': 205,\n",
       " 'who': 206,\n",
       " 'beauty': 207,\n",
       " 'their': 208,\n",
       " 'dreams': 209,\n",
       " 'lives': 210,\n",
       " 'begin': 211,\n",
       " 'end': 212,\n",
       " 'day': 213,\n",
       " 'silent': 214,\n",
       " 'want': 215,\n",
       " 'someone': 216,\n",
       " 'either': 217,\n",
       " 'daring': 218,\n",
       " 'adventure': 219,\n",
       " 'at': 220,\n",
       " 'all': 221,\n",
       " 'revenge': 222,\n",
       " 'massive': 223,\n",
       " 'dwell': 224,\n",
       " 'past': 225,\n",
       " 'concentrate': 226,\n",
       " 'moment': 227,\n",
       " 'secret': 228,\n",
       " 'ahead': 229,\n",
       " 'started': 230,\n",
       " 'never': 231,\n",
       " 'too': 232,\n",
       " 'late': 233,\n",
       " 'might': 234,\n",
       " 'been': 235,\n",
       " 'doing': 236,\n",
       " 'successful': 237,\n",
       " 'most': 238,\n",
       " 'beautiful': 239,\n",
       " 'cannot': 240,\n",
       " 'seen': 241,\n",
       " 'even': 242,\n",
       " 'touched': 243,\n",
       " 'they': 244,\n",
       " 'felt': 245,\n",
       " 'heart': 246,\n",
       " 'watch': 247,\n",
       " 'clock': 248,\n",
       " 'going': 249}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "249"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok_dict = tokenizer.word_index\n",
    "tok_len = len(tokenizer.word_index)\n",
    "tok_len\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokized_sequnece = tokenizer.texts_to_sequences(quotes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 23, 46, 22, 10, 3, 115, 8, 115, 116], [2, 144, 106, 145, 1, 146]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokized_sequnece[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_seq = []\n",
    "\n",
    "for sentence in quotes.str.split('\\n'):\n",
    "#     print(sentence)\n",
    "    tokenized_sen = tokenizer.texts_to_sequences(sentence)[0]\n",
    "    \n",
    "#   below code create sub_sequence\n",
    "# Example with tokenized_sen = [1, 2, 3]:\n",
    "# Iteration 1: tokenized_sen[:2] → [1, 2]\n",
    "# Iteration 2: tokenized_sen[:3] → [1, 2, 3]\n",
    "    for i in range(1,len(tokenized_sen)):\n",
    "        input_seq.append(tokenized_sen[:i+1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7707"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_seq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = max([len(x) for x in input_seq])\n",
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  2, 23],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  2, 23, 46]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_padded = pad_sequences(input_seq,maxlen=max_len,padding='pre')\n",
    "x_padded[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x_padded[:,:-1]\n",
    "y = x_padded[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7707, 23), (7707,))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape,y.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "y = to_categorical(y, num_classes=tok_len+1)\n",
    "y[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=250,output_dim=100,input_shape=(23,)))\n",
    "model.add(LSTM(150,return_sequences=True))\n",
    "model.add(LSTM(150,return_sequences=True))\n",
    "model.add(LSTM(128))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(Dense(250,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 23, 100)           25000     \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 23, 150)           150600    \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 23, 150)           180600    \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 128)               142848    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 250)               32250     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 531298 (2.03 MB)\n",
      "Trainable params: 531298 (2.03 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "241/241 [==============================] - 39s 114ms/step - loss: 4.5589 - accuracy: 0.0753\n",
      "Epoch 2/15\n",
      "241/241 [==============================] - 34s 143ms/step - loss: 4.1197 - accuracy: 0.1246\n",
      "Epoch 3/15\n",
      "241/241 [==============================] - 32s 134ms/step - loss: 2.3693 - accuracy: 0.4711\n",
      "Epoch 4/15\n",
      "241/241 [==============================] - 28s 117ms/step - loss: 1.1393 - accuracy: 0.8538\n",
      "Epoch 5/15\n",
      "241/241 [==============================] - 25s 104ms/step - loss: 0.6782 - accuracy: 0.9052\n",
      "Epoch 6/15\n",
      "241/241 [==============================] - 23s 97ms/step - loss: 0.4885 - accuracy: 0.9227\n",
      "Epoch 7/15\n",
      "241/241 [==============================] - 24s 100ms/step - loss: 0.3902 - accuracy: 0.9282\n",
      "Epoch 8/15\n",
      "241/241 [==============================] - 27s 111ms/step - loss: 0.3318 - accuracy: 0.9293\n",
      "Epoch 9/15\n",
      "241/241 [==============================] - 22s 92ms/step - loss: 0.2942 - accuracy: 0.9324\n",
      "Epoch 10/15\n",
      "241/241 [==============================] - 21s 88ms/step - loss: 0.2639 - accuracy: 0.9376\n",
      "Epoch 11/15\n",
      "241/241 [==============================] - 21s 89ms/step - loss: 0.2370 - accuracy: 0.9402\n",
      "Epoch 12/15\n",
      "241/241 [==============================] - 23s 94ms/step - loss: 0.2123 - accuracy: 0.9441\n",
      "Epoch 13/15\n",
      "241/241 [==============================] - 21s 89ms/step - loss: 0.1931 - accuracy: 0.9473\n",
      "Epoch 14/15\n",
      "241/241 [==============================] - 22s 89ms/step - loss: 0.1768 - accuracy: 0.9504\n",
      "Epoch 15/15\n",
      "241/241 [==============================] - 21s 88ms/step - loss: 0.1621 - accuracy: 0.9524\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1365e5e3b20>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x,y,epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lenovo\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('quote_writer.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"new_tokenizer.pkl\", \"wb\") as f:\n",
    "    pickle.dump(tokenizer, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "saved_model = tf.keras.models.load_model(\"quote_writer.h5\")\n",
    "\n",
    "saved_tokenizer = pickle.load(open(\"tokenizer_of_quotes.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[35]\n",
      "1/1 [==============================] - 0s 221ms/step\n",
      "1\n",
      "Believe you\n",
      "[35, 1]\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "7\n",
      "Believe you can\n",
      "[35, 1, 7]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "11\n",
      "Believe you can and\n",
      "[35, 1, 7, 11]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "34\n",
      "Believe you can and you're\n",
      "[35, 1, 7, 11, 34]\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "52\n",
      "Believe you can and you're halfway\n"
     ]
    }
   ],
   "source": [
    "user_text = \"Believe\"\n",
    "\n",
    "for i in range(5):\n",
    "    text_token = saved_tokenizer.texts_to_sequences([user_text])[0]\n",
    "    print(text_token)\n",
    "    input_x = pad_sequences([text_token],maxlen=23,padding='pre')\n",
    "    predictions = saved_model.predict(input_x)\n",
    "    pos=np.argmax(predictions)\n",
    "    print(pos)\n",
    "    for word, index in saved_tokenizer.word_index.items():\n",
    "        if index == pos:\n",
    "            user_text = user_text+' '+word\n",
    "            print(user_text)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
